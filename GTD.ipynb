{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edpDUM8kZkft"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import decomposition\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    \n",
    "    #Read the data from the csv file, to replicate the behavior on another mc, change the path of file accordingly\n",
    "    print(\"------------------------Reading file from csv-----------------------------------------------\")\n",
    "    df = pd.read_csv(filepath, encoding='ISO-8859-1', delimiter = ',')\n",
    "    \n",
    "    #Set the display max option to desired rows and colwidth\n",
    "    pd.set_option('display.max_colwidth',150)\n",
    "    pd.set_option('display.max_rows', 181691)\n",
    "    \n",
    "    print(\"-----------------------Finished Reading the File-------------------------------------------\")\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmc8NT85vcxn"
   },
   "outputs": [],
   "source": [
    "def eda(df):\n",
    "    \n",
    "    print(\"---------------------Exploratory Data Analysis------------------------------------------------\")\n",
    "    print(\"type of df \", type(df))\n",
    "    print(\"shape and size of df \", df.shape, df.size)\n",
    "#     print(\"index of df \", df.index)\n",
    "#     print(\"df.head(10) \", df.head(10))\n",
    "#     print(\"df.tail(10)\", df.tail(10))\n",
    "#     print(\"df.info \", df.info)\n",
    "#     print(\"df.describe \", df.describe)\n",
    "#     print(\"df.columns \", df.columns)\n",
    "#     print(\"df.dtypes \", df.dtypes)\n",
    "#     print(\"Plot of Kills vs Years\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L0Z-t20W6K9j",
    "outputId": "bdda10f3-1b58-4277-8d78-87523817a1cb"
   },
   "outputs": [],
   "source": [
    "def explore_target(df):\n",
    "    \n",
    "    print(\"--------------------------- Exploring Target -----------------------------------------\")\n",
    "    dfGname = df['gname'].rank\n",
    "#     print(\"Ranked gnames \", dfGname) # doesn't have head function\n",
    "#     print(df['gname'].value_counts())\n",
    "\n",
    "def reduction(df):    \n",
    "    \n",
    "    print(\"--------------------------- Reduction of Data ----------------------------------------\")\n",
    "    #drop rows which have gname as Unknown\n",
    "    type(df['gname']) #pandas.core.series.Series\n",
    "    # type('Unknown') #String\n",
    "\n",
    "    # Get names of indexes for which column gname has value Unknown\n",
    "    indexNames = df[ df['gname']=='Unknown' ].index\n",
    "    print(len(indexNames))\n",
    "\n",
    "    # Delete these row indexes from dataFrame\n",
    "    df.drop(indexNames , inplace=True)\n",
    "    print(df.shape)\n",
    "#     print(df.head(5))  \n",
    "    \n",
    "    #Check if the above drop removed Unknown gname\n",
    "    df['gname'].value_counts()\n",
    "    \n",
    "    #Select the top 10 terrorist groups per the no. of attacks they made\n",
    "    gname_selected = df['gname'].value_counts().head(10)\n",
    "    print(\"top 10 prolific gnames are\",gname_selected)\n",
    "    \n",
    "    #reduce the df with these selected gname\n",
    "    print(\"--------------------------Shape before Reduction ---------------------\")\n",
    "    print(df.shape)\n",
    "    df = df.loc[df['gname'].isin(gname_selected.index)]\n",
    "    print(\"--------------------------Shape after Reduction ---------------------\")\n",
    "    print(df.shape)\n",
    "\n",
    "    print(df['gname'].head(5))\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_1(df):\n",
    "    \n",
    "    print(\"---------------------preprocessing using various techniques-----------------------------------\")\n",
    "    \n",
    "    #Preprocessing - Missing Values\n",
    "    print(\"---------------------Removing and Imputing Missing Values-------------------------------------\")\n",
    "    removed_missing_val_df = missing_values(df)\n",
    "    \n",
    "    #Preprocessing - Encoding Categorial Features and Target\n",
    "    print(\"---------------------Encoding--------------------------------\")\n",
    "    encoded_df = encoding(removed_missing_val_df)\n",
    "\n",
    "def preprocessing_data_2(reduced_features_df):\n",
    "    #Preprocessing - Checking Imbalance in Data\n",
    "    check_imbalance(reduced_features_df, train_labels) \n",
    "    \n",
    "    #Preprocessing - Checking Outliers\n",
    "    outliers(train_features)    \n",
    "    \n",
    "    #Preprocessing - Scaling\n",
    "    scaling(train_features)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model_name, train_features,test_features, train_labels, test_labels):\n",
    "    \n",
    "    if(model_name == 'knn'):\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "        scores = model_selection.cross_val_score(knn , train_features , train_labels , cv=10)\n",
    "        print (\"scores.mean()\" , scores.mean())\n",
    "        param_grid = [ {'n_neighbors': list(range(1, 80)), 'p':[1, 2, 3, 4, 5] }]\n",
    "        clf = GridSearchCV(KNeighborsClassifier (), param_grid , cv=10, n_jobs=-1)\n",
    "        clf.fit(train_features , train_labels)\n",
    "        \n",
    "        print(\"n Best parameters set found on development set:\")\n",
    "        print(clf.best_params_ , \"with a score of \", clf.best_score_)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "#         scores.mean() 0.9712069548279167\n",
    "#         n Best parameters set found on development set:\n",
    "#         {'n_neighbors': 4, 'p': 1} with a score of  0.9821346398505806\n",
    "        grid_accuracy = evaluate(best_grid, test_features, test_labels)\n",
    "        print(\"best_grid\", best_grid)\n",
    "        print(\"grid_accuracy\", grid_accuracy)\n",
    "        \n",
    "#         print (clf.score(test_features, test_labels)) \n",
    "    \n",
    "    if(model_name == 'decision_tree'):\n",
    "        \n",
    "        decTree = DecisionTreeClassifier()\n",
    "        scores = model_selection.cross_val_score(decTree , train_features , train_labels , cv=10)\n",
    "        print (\"scores.mean()\" , scores.mean())\n",
    "        param_grid = [ {'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}]\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), param_grid , cv=10, n_jobs=-1)\n",
    "        clf.fit(train_features , train_labels)\n",
    "\n",
    "        print(\"n Best parameters set found on development set:\")\n",
    "        print(clf.best_params_ , \"with a score of \", clf.best_score_)\n",
    "     \n",
    "        accuracy = clf.score(test_features, test_labels)\n",
    "        print (\"Decision Tree Accuracy \", accuracy)\n",
    "    \n",
    "    if(model_name == 'random_forest'):\n",
    "        #Random forest is an ensemble technique\n",
    "        # Creating param grid\n",
    "        \n",
    "        param_grid = {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [80, 100],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 5],\n",
    "            'min_samples_split': [ 10, 15],\n",
    "            'n_estimators': [100, 500, 1000]\n",
    "        }\n",
    "        \n",
    "        rf = RandomForestClassifier()\n",
    "        grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                  cv = 10, n_jobs = -1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "        \n",
    "        best_grid = grid_search.best_estimator_\n",
    "        grid_accuracy = evaluate(best_grid, test_features, test_labels)\n",
    "        print(\"best_grid\", best_grid)\n",
    "        print(\"grid_accuracy\", grid_accuracy)\n",
    "    \n",
    "    #Model Persistence\n",
    "    \n",
    "    if(model_name == 'naive_bayes'):\n",
    "        print(\"Using Naive Bayes\")\n",
    "        \n",
    "        nBayes = GaussianNB()\n",
    "        nBayes = nBayes.fit(train_features, train_labels)\n",
    "        accuracy = nBayes.score(test_features, test_labels)\n",
    "        print (\"Naive Bayes Accuracy \", accuracy)\n",
    "\n",
    "    \n",
    "    if(model_name == 'svm'):\n",
    "        print(\"Using SVM\")\n",
    "       \n",
    "        svc = SVC(gamma='auto')\n",
    "        svc = svc.fit(train_features, train_labels)\n",
    "#         accuracy = svc.score(test_features, test_labels)\n",
    "        accuracy = evaluate(svc, test_features, test_labels)\n",
    "        print (\"SVM Accuracy \", accuracy)  \n",
    "\n",
    "# def evaluate(model, test_features, test_labels):\n",
    "#     predictions = model.predict(test_features)\n",
    "#     errors = abs(predictions - test_labels)\n",
    "#     mape = 100 * np.mean(errors / test_labels)\n",
    "#     accuracy = 100 - mape\n",
    "#     print('Model Performance')\n",
    "#     print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "#     print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    \n",
    "    y_preds = model.predict(test_features)\n",
    "\n",
    "    # Accuracy Score using score method\n",
    "    accuracy_score = model.score(test_features, test_labels)\n",
    "    print (\"Accuracy \", model, accuracy_score)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    # Accuracy in machine learning algorithm is measured as:\n",
    "    #               𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝑇𝑟𝑢𝑒𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒𝑠\n",
    "    #   --------------------------------------------------      \n",
    "    # 𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝐹𝑎𝑙𝑠𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝑇𝑟𝑢𝑒𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒𝑠+𝐹𝑎𝑙𝑠𝑒𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒𝑠\n",
    "    \n",
    "    confusion_mat= confusion_matrix(y_true= test_labels , y_pred=y_preds)\n",
    "    print('Confusion matrix:n', confusion_mat)\n",
    "#     Error - Classification metrics can't handle a mix of unknown and multiclass targets\n",
    "    \n",
    "    # F1 score\n",
    "    f1score = f1_score(test_labels,y_preds, average = 'micro') #average = binary doesn't work\n",
    "    print(\"f1score is\", f1score)\n",
    "    \n",
    "    # Classification Report which shows Precision, Recall, F1Score and Support\n",
    "    class_report = classification_report(test_labels,y_preds) #make sure to put test_labels in the method instead of test_features\n",
    "    print(\"class_report is\", class_report)\n",
    "    \n",
    "    # Measures of error, accuracy \n",
    "    \n",
    "    errors = abs(y_preds - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "doAqG_fAASTJ",
    "outputId": "e5465c26-d807-4883-e14b-5c5814c03b3a"
   },
   "outputs": [],
   "source": [
    "def outliers(features):\n",
    "    \n",
    "    #Checking Outliers - non standard missing vales such as ? or \" \" etc. can be spotted via outlier detection\n",
    "    #if missed during data exploration stage\n",
    "#     sns.boxplot(data= pd.DataFrame(train_features))\n",
    "    sns.boxplot(data = features)\n",
    "    plt.show()\n",
    "           \n",
    "#     rowsToDelete = features.iloc[:,9]>750\n",
    "#     features = features[rowsToDelete]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CMUjMS9JTQMA",
    "outputId": "1df85925-3708-42cd-e511-32b01ada17b3"
   },
   "outputs": [],
   "source": [
    "def missing_values(technique, df):\n",
    "    \n",
    "    print(\" df.isnull().sum() \",df.isnull().sum())\n",
    "    print(type(df.shape))\n",
    "\n",
    "    if(technique == 'impute'):\n",
    "        #     non_missing_values_in_a_col = .3 * n_rows\n",
    "        print(\"Dropping Columns which don't have atleast 20,000 non nan values\")\n",
    "        df = df.dropna(thresh=20000, axis=1)\n",
    "\n",
    "        print(\"Imputing the rest of the nan values\")\n",
    "        imputer = SimpleImputer(missing_values= np.nan, strategy='most_frequent')\n",
    "        imputer.fit(df)\n",
    "        allValues = imputer.transform(df)\n",
    "        df = pd.DataFrame(data = allValues, columns=df.columns)\n",
    "    \n",
    "    if(technique == 'delete_cols'):\n",
    "        print(\"Dropping all Columns with nan values\")\n",
    "        df = df.dropna(axis=1)\n",
    "        \n",
    "    if(technique == 'delete_rows'):\n",
    "        print(\"Dropping all rows with nan values\")\n",
    "        df = df.dropna(axis=0)\n",
    "     \n",
    "    if(technique == 'delete_rows_with_threshold'):\n",
    "        df.dropna(thresh=35)\n",
    "    \n",
    "    print(type(df.shape))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_target(df):\n",
    "    \n",
    "    #converting categorical data to numerical data\n",
    "    print(\"---------------- converting categorical target to numerical data-------------------\")\n",
    "    \n",
    "    df['city'].unique().shape\n",
    "    # cityEncoded =  encoder.fit_transform( df[[\"city\"]] ) - led to crash of the notebook\n",
    "    df = df.drop(['city'], axis=1)\n",
    "    df.head(5)\n",
    "    \n",
    "    print(\" df['gname'].unique().shape \",df['gname'].unique().shape)\n",
    "    #gname is my class or y, using Label encoder \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    gnameEncoded =  le.fit_transform( df[[\"gname\"]] )\n",
    "    df['gnameEncoded'] = gnameEncoded\n",
    "    df = df.drop('gname', axis =1)\n",
    "    print(df.head(5))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def encoding_features(features):\n",
    "    \n",
    "    #converting categorical features to numerical data\n",
    "    print(\"---------------- converting categorical features to numerical data-------------------\")\n",
    "    encoder = OneHotEncoder(sparse = False)\n",
    "    \n",
    "    features_encoded = encoder.fit_transform(features)\n",
    "    print(\"features_encoded\",features_encoded) # this converts into numpy array\n",
    "    \n",
    "    return features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(technique, reduced_features_df, train_features,train_labels):\n",
    "    \n",
    "    if(technique == 'dimensionality_reduction'):\n",
    "        dimensionality_reduction(train_features)\n",
    "            \n",
    "    if(technique == 'univariate_selection'):\n",
    "        univariate_selection(train_features,train_labels)       \n",
    "\n",
    "    if(technique == 'feature_importance'):\n",
    "        feature_importance(train_features,train_labels)  \n",
    "        \n",
    "    if(technique == 'correlation_matrix'):\n",
    "        correlation_matrix(reduced_features_df)\n",
    "\n",
    "    if(technique == 'greedy_feature_selection'):\n",
    "        greedy_feature_selection(train_features,train_labels)    \n",
    "\n",
    "    \n",
    "#     tree_based_feature_selection(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(df, target):\n",
    "    \n",
    "    #Checking Imbalance in Dataset\n",
    "    targets = df.gnameEncoded.value_counts() #this returns a series\n",
    "    #     print (\"Minority class represents just \",(targets[1]/len(df))*100, \" % of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "   \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \n",
    "    y = df.loc[:,'gnameEncoded']\n",
    "    X = df.loc[:, df.columns != 'gnameEncoded']\n",
    "    \n",
    "    train_features, test_features, train_labels, test_labels = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    print(train_features.shape, train_labels.shape)\n",
    "    print(test_features.shape, test_labels.shape)\n",
    "    \n",
    "    return train_features,test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_features_by_intuition(df):\n",
    "    \n",
    "    # Selected columns by intuition     \n",
    "    col_selected = ['iyear', 'imonth', 'iday', 'country', 'region', 'success', 'suicide', 'attacktype1', 'targtype1', 'natlty1',\n",
    "       'gnameEncoded', 'guncertain1', 'individual', 'weaptype1']\n",
    "    df = df[col_selected]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction(features):\n",
    "    \n",
    "    print(\"-------------------------Dimensionality Reduction-------------------------------------\")\n",
    "    \n",
    "    pca = decomposition.PCA(n_components = 10) #n_components has to be less than the actual columns in df \n",
    "    pca.fit(features) \n",
    "    X=pca.transform(features)\n",
    "    print (\"Explained Variance is: \", np.sum(pca.explained_variance_ratio_ ))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_selection(X,y):\n",
    "    \n",
    "    print(\"------------------------Univariate Selection----------------------------------\")\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X,y):\n",
    "    \n",
    "    print(\"------------------------Feature Importance----------------------------------\")\n",
    "    \n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X,y)\n",
    "    print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "    #plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    \n",
    "    print(\"------------------------Correlation Matrix with Heatmap----------------------------------\")\n",
    "    \n",
    "    #get correlations of each features in dataset\n",
    "    \n",
    "    corr = df.corr()\n",
    "    plt.figure(figsize=(14,6))\n",
    "    ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0,cmap=sns.diverging_palette(20, 220, n=200),square=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_feature_selection(X,y):\n",
    " \n",
    "    print(\"-----------------------------Greedy Feature Selection---------------------------------------------\")\n",
    "    \n",
    "    decTree = DecisionTreeClassifier()\n",
    "    scores = model_selection.cross_val_score(decTree,X, y, cv=10)\n",
    "    print ('Initial Result',scores.mean())\n",
    "    estimator = linear_model.LogisticRegression(multi_class ='auto', solver='lbfgs')\n",
    "    rfecv = RFECV(estimator, cv=10)\n",
    "    rfecv.fit(X,y)\n",
    "    # optimal number of features\n",
    "    print (rfecv.n_features_ )\n",
    "    # ranking of each feature\n",
    "    print (rfecv.ranking_ )\n",
    "    # select highest ranked features and build a new model\n",
    "    X = X.iloc[ : ,rfecv.support_ ]\n",
    "    decTree = DecisionTreeClassifier()\n",
    "    scores = model_selection.cross_val_score(decTree , X, y, cv=10)\n",
    "    print ('Result after greedy feature selection: ',scores.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Reading the Data from File-------------------------------------------------\n",
      "------------------------Reading file from csv-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Finished Reading the File-------------------------------------------\n",
      "---------------------Explorartory Data Analysis-------------------------------------------------\n",
      "---------------------Exploratory Data Analysis------------------------------------------------\n",
      "type of df  <class 'pandas.core.frame.DataFrame'>\n",
      "shape and size of df  (181691, 135) 24528285\n",
      "---------------------Reducing the data based for top 10 gnames only-----------------------------\n",
      "--------------------------- Exploring Target -----------------------------------------\n",
      "--------------------------- Reduction of Data ----------------------------------------\n",
      "82782\n",
      "(98909, 135)\n",
      "top 10 prolific gnames are Taliban                                             7478\n",
      "Islamic State of Iraq and the Levant (ISIL)         5613\n",
      "Shining Path (SL)                                   4555\n",
      "Farabundo Marti National Liberation Front (FMLN)    3351\n",
      "Al-Shabaab                                          3288\n",
      "New People's Army (NPA)                             2772\n",
      "Irish Republican Army (IRA)                         2671\n",
      "Revolutionary Armed Forces of Colombia (FARC)       2487\n",
      "Boko Haram                                          2418\n",
      "Kurdistan Workers' Party (PKK)                      2310\n",
      "Name: gname, dtype: int64\n",
      "--------------------------Shape before Reduction ---------------------\n",
      "(98909, 135)\n",
      "--------------------------Shape after Reduction ---------------------\n",
      "(36943, 135)\n",
      "39         New People's Army (NPA)\n",
      "169        New People's Army (NPA)\n",
      "364    Irish Republican Army (IRA)\n",
      "365    Irish Republican Army (IRA)\n",
      "366    Irish Republican Army (IRA)\n",
      "Name: gname, dtype: object\n",
      "---------------------Removing and Imputing Missing Values---------------------------------------\n",
      " df.isnull().sum()  eventid                   0\n",
      "iyear                     0\n",
      "imonth                    0\n",
      "iday                      0\n",
      "approxdate            34216\n",
      "extended                  0\n",
      "resolution            36614\n",
      "country                   0\n",
      "country_txt               0\n",
      "region                    0\n",
      "region_txt                0\n",
      "provstate                13\n",
      "city                     75\n",
      "latitude               1244\n",
      "longitude              1244\n",
      "specificity               2\n",
      "vicinity                  0\n",
      "location              26532\n",
      "summary               13631\n",
      "crit1                     0\n",
      "crit2                     0\n",
      "crit3                     0\n",
      "doubtterr                 0\n",
      "alternative           28604\n",
      "alternative_txt       28604\n",
      "multiple                  0\n",
      "success                   0\n",
      "suicide                   0\n",
      "attacktype1               0\n",
      "attacktype1_txt           0\n",
      "attacktype2           35050\n",
      "attacktype2_txt       35050\n",
      "attacktype3           36781\n",
      "attacktype3_txt       36781\n",
      "targtype1                 0\n",
      "targtype1_txt             0\n",
      "targsubtype1           1390\n",
      "targsubtype1_txt       1390\n",
      "corp1                  7158\n",
      "target1                  57\n",
      "natlty1                 314\n",
      "natlty1_txt             314\n",
      "targtype2             33753\n",
      "targtype2_txt         33753\n",
      "targsubtype2          33794\n",
      "targsubtype2_txt      33794\n",
      "corp2                 33929\n",
      "target2               33763\n",
      "natlty2               33785\n",
      "natlty2_txt           33785\n",
      "targtype3             36577\n",
      "targtype3_txt         36577\n",
      "targsubtype3          36592\n",
      "targsubtype3_txt      36592\n",
      "corp3                 36606\n",
      "target3               36574\n",
      "natlty3               36576\n",
      "natlty3_txt           36576\n",
      "gname                     0\n",
      "gsubname              34882\n",
      "gname2                36646\n",
      "gsubname2             36915\n",
      "gname3                36920\n",
      "gsubname3             36943\n",
      "motive                30477\n",
      "guncertain1               1\n",
      "guncertain2           36662\n",
      "guncertain3           36920\n",
      "individual                0\n",
      "nperps                13275\n",
      "nperpcap              13903\n",
      "claimed               13629\n",
      "claimmode             28885\n",
      "claimmode_txt         28885\n",
      "claim2                36668\n",
      "claimmode2            36875\n",
      "claimmode2_txt        36875\n",
      "claim3                36920\n",
      "claimmode3            36940\n",
      "claimmode3_txt        36940\n",
      "compclaim             36297\n",
      "weaptype1                 0\n",
      "weaptype1_txt             0\n",
      "weapsubtype1           5432\n",
      "weapsubtype1_txt       5432\n",
      "weaptype2             33018\n",
      "weaptype2_txt         33018\n",
      "weapsubtype2          33613\n",
      "weapsubtype2_txt      33613\n",
      "weaptype3             36326\n",
      "weaptype3_txt         36326\n",
      "weapsubtype3          36371\n",
      "weapsubtype3_txt      36371\n",
      "weaptype4             36920\n",
      "weaptype4_txt         36920\n",
      "weapsubtype4          36920\n",
      "weapsubtype4_txt      36920\n",
      "weapdetail            15057\n",
      "nkill                  3274\n",
      "nkillus               13325\n",
      "nkillter              14528\n",
      "nwound                 5585\n",
      "nwoundus              13384\n",
      "nwoundte              15377\n",
      "property                  0\n",
      "propextent            23628\n",
      "propextent_txt        23628\n",
      "propvalue             27072\n",
      "propcomment           25469\n",
      "ishostkid                 1\n",
      "nhostkid              33701\n",
      "nhostkidus            33712\n",
      "nhours                35909\n",
      "ndays                 35033\n",
      "divert                36916\n",
      "kidhijcountry         36558\n",
      "ransom                20792\n",
      "ransomamt             36809\n",
      "ransomamtus           36875\n",
      "ransompaid            36861\n",
      "ransompaidus          36875\n",
      "ransomnote            36855\n",
      "hostkidoutcome        34213\n",
      "hostkidoutcome_txt    34213\n",
      "nreleased             34308\n",
      "addnotes              29737\n",
      "scite1                13638\n",
      "scite2                19802\n",
      "scite3                26491\n",
      "dbsource                  0\n",
      "INT_LOG                   0\n",
      "INT_IDEO                  0\n",
      "INT_MISC                  0\n",
      "INT_ANY                   0\n",
      "related               29376\n",
      "dtype: int64\n",
      "<class 'tuple'>\n",
      "Dropping Columns which don't have atleast 20,000 non nan values\n",
      "Imputing the rest of the nan values\n",
      "<class 'tuple'>\n",
      "---------------------Encoding Target----------------------------------------------------------- \n",
      "---------------- converting categorical target to numerical data-------------------\n",
      " df['gname'].unique().shape  (10,)\n",
      "        eventid iyear imonth iday extended country     country_txt region  \\\n",
      "0  197001310001  1970      1   31        0     160     Philippines      5   \n",
      "1  197004020001  1970      4    2        0     160     Philippines      5   \n",
      "2  197006260001  1970      6   26        0     603  United Kingdom      8   \n",
      "3  197006270001  1970      6   27        0     603  United Kingdom      8   \n",
      "4  197006270002  1970      6   27        0     603  United Kingdom      8   \n",
      "\n",
      "       region_txt         provstate  ... nwoundte property ishostkid  \\\n",
      "0  Southeast Asia            Tarlac  ...        0        0         0   \n",
      "1  Southeast Asia          Pampanga  ...        0        0         0   \n",
      "2  Western Europe  Northern Ireland  ...        0        1         0   \n",
      "3  Western Europe  Northern Ireland  ...        0        0         0   \n",
      "4  Western Europe  Northern Ireland  ...        0        0         0   \n",
      "\n",
      "                                                                               scite1  \\\n",
      "0  \"ISIS detonates 5 empty homes in Daur using IEDs,\" Iraqi News, September 28, 2016.   \n",
      "1  \"ISIS detonates 5 empty homes in Daur using IEDs,\" Iraqi News, September 28, 2016.   \n",
      "2  \"ISIS detonates 5 empty homes in Daur using IEDs,\" Iraqi News, September 28, 2016.   \n",
      "3  \"ISIS detonates 5 empty homes in Daur using IEDs,\" Iraqi News, September 28, 2016.   \n",
      "4  \"ISIS detonates 5 empty homes in Daur using IEDs,\" Iraqi News, September 28, 2016.   \n",
      "\n",
      "  dbsource INT_LOG INT_IDEO INT_MISC INT_ANY gnameEncoded  \n",
      "0     PGIS       0        1        1       1            6  \n",
      "1     PGIS       0        1        1       1            6  \n",
      "2     CAIN       0        0        1       1            3  \n",
      "3     CAIN       0        0        1       1            3  \n",
      "4     CAIN       0        0        1       1            3  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "---------------------Feature Selection by Exploration of Data---------------------------------- \n",
      "---------------------Splitting Data into train and test --------------------------------------- \n",
      "(29554, 13) (29554,)\n",
      "(7389, 13) (7389,)\n",
      "---------------------Check Imbalance ---------------------------------------------------------- \n",
      "---------------------Check and process outliers ----------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Scaling of Features data ------------------------------------------------- \n",
      "--------------------Other Feature Selection Techniques ---------------------------------------- \n",
      "-----------------------------Greedy Feature Selection---------------------------------------------\n",
      "Initial Result 0.9951268659526008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[ 3  8  7  1  1 11 10  6  4  2  9 12  5]\n",
      "Result after greedy feature selection:  0.9946193662141741\n",
      "---------Modelling, Hyper Parameter Optimization, Cross Fold, Grid Search, Ensemble------------ \n",
      "Accuracy  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=100, max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) 0.9966165922316957\n",
      "Confusion matrix:n [[ 679    0    0    0    0    0    0    0    0    0]\n",
      " [   1  463    0    0    0    0    0    0    0    0]\n",
      " [   0    0  683    0    0    0    0    0    0    0]\n",
      " [   0    0    0  518    0    1    0    0    0    0]\n",
      " [   0    1    0    0 1080    9    5    0    0    0]\n",
      " [   0    0    0    0    2  488    0    0    0    0]\n",
      " [   0    0    0    0    0    0  528    0    0    1]\n",
      " [   0    0    0    0    0    0    0  484    3    0]\n",
      " [   0    0    0    0    0    0    0    1  913    0]\n",
      " [   0    0    0    0    0    1    0    0    0 1528]]\n",
      "f1score is 0.9966165922316957\n",
      "class_report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       679\n",
      "           1       1.00      1.00      1.00       464\n",
      "           2       1.00      1.00      1.00       683\n",
      "           3       1.00      1.00      1.00       519\n",
      "           4       1.00      0.99      0.99      1095\n",
      "           5       0.98      1.00      0.99       490\n",
      "           6       0.99      1.00      0.99       529\n",
      "           7       1.00      0.99      1.00       487\n",
      "           8       1.00      1.00      1.00       914\n",
      "           9       1.00      1.00      1.00      1529\n",
      "\n",
      "    accuracy                           1.00      7389\n",
      "   macro avg       1.00      1.00      1.00      7389\n",
      "weighted avg       1.00      1.00      1.00      7389\n",
      "\n",
      "Model Performance\n",
      "Average Error: 0.0051 degrees.\n",
      "Accuracy = 99.86%.\n",
      "best_grid RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=100, max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "grid_accuracy 99.8649078608095\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    filepath = 'C:/Users/jagri/Downloads/MachineLearning/gtd/globalterrorismdb.csv' \n",
    "    #Read Data\n",
    "    print(\"---------------------Reading the Data from File-------------------------------------------------\")\n",
    "    df = read_data(filepath)\n",
    "    \n",
    "    #Exploratory Data Analysis\n",
    "    print(\"---------------------Explorartory Data Analysis-------------------------------------------------\")\n",
    "    eda(df)\n",
    "    \n",
    "    #Reducing the data based on top 10 gname or terrorist groups as data is quite huge\n",
    "    print(\"---------------------Reducing the data based for top 10 gnames only-----------------------------\")\n",
    "    explore_target(df)\n",
    "    reduced_df = reduction(df)\n",
    "    \n",
    "    #Preprocessing - Missing Values\n",
    "    print(\"---------------------Removing and Imputing Missing Values---------------------------------------\")\n",
    "    removed_missing_val_df = missing_values('impute',reduced_df)\n",
    "    \n",
    "    #Preprocessing - Encoding Categorial Target\n",
    "    print(\"---------------------Encoding Target----------------------------------------------------------- \")\n",
    "    encoded_target_df = encoding_target(removed_missing_val_df)\n",
    "    \n",
    "    # Feature Selection by Exploration of Data\n",
    "    print(\"---------------------Feature Selection by Exploration of Data---------------------------------- \")\n",
    "    reduced_features_df =selecting_features_by_intuition(encoded_target_df)\n",
    "\n",
    "    #Splitting the Data for further preprocessing data\n",
    "    print(\"---------------------Splitting Data into train and test --------------------------------------- \")\n",
    "    train_features,test_features, train_labels, test_labels = split_data(reduced_features_df)\n",
    "    \n",
    "    #Preprocessing - Check Imbalance\n",
    "    print(\"---------------------Check Imbalance ---------------------------------------------------------- \")\n",
    "    check_imbalance(reduced_features_df, train_labels) \n",
    "    \n",
    "    #Preprocessing - Check and process outliers\n",
    "    print(\"---------------------Check and process outliers ----------------------------------------------- \")\n",
    "    outliers(train_features)    \n",
    "    \n",
    "    #Preprocess scaling\n",
    "    print(\"---------------------Scaling of Features data ------------------------------------------------- \")\n",
    "    scaling(train_features)\n",
    "    \n",
    "#     #Visualizing Other Feature Selection Techniques\n",
    "    print(\"--------------------Other Feature Selection Techniques ---------------------------------------- \")\n",
    "    feature_selection('greedy_feature_selection', reduced_features_df, train_features, train_labels)\n",
    "    \n",
    "    #Modelling, Hyper Parameter Optimization, Cross Fold, Grid Search, Ensemble\n",
    "    print(\"---------Modelling, Hyper Parameter Optimization, Cross Fold, Grid Search, Ensemble------------ \")\n",
    "\n",
    "    model_name = 'random_forest'\n",
    "    model(model_name, train_features,test_features, train_labels, test_labels)\n",
    "\n",
    "    #evaluation() -- being called from model methods individually\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GTD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
